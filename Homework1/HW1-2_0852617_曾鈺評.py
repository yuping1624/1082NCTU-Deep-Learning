# -*- coding: utf-8 -*-
"""HW1-2_0852617_曾鈺評.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/182rKnsAT5DmRYgW9S-wgyDhuubwZzj5m
"""

import os
import numpy as np
import cv2
import torch
import torch.nn
import torch.utils.data
import torch.nn.functional as F
import torchvision.transforms as transforms
import pandas as pd
from sklearn.preprocessing import LabelEncoder
import sklearn.metrics
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
import time
from PIL import Image



import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        #crop = transforms.Scale(12)
        
        #filename.transform{}
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.

x_train_crop = np.load("/kaggle/input/cnn-hw1-2/train_crop.npy", allow_pickle=True)

x_test_crop = np.load("/kaggle/input/cnn-hw1-2/test_crop.npy", allow_pickle=True)

trainset = pd.read_csv("/kaggle/input/cnn-hw1-2/train.csv")
trainset["filename_e"] = trainset["filename"].str.replace('+', '')
trainset["filename_e"] = trainset["filename_e"].str.replace('@', '')
trainset["filename_e"] = trainset["filename_e"].str.replace('&', '')
trainset["filename_e"] = trainset["filename_e"].str.replace('!', '')
trainset["filename_e"] = trainset["filename_e"].str.replace('=exif=', '_exif')

trainset

testset = pd.read_csv("/kaggle/input/cnn-hw1-2/test.csv")
testset["filename_e"] = testset["filename"].str.replace('+', '')
testset

le = LabelEncoder()
trainset['encoded_labels'] = le.fit_transform(trainset['label'])
le = LabelEncoder()
testset['encoded_labels'] = le.fit_transform(testset['label'])





transform1 = transforms.Compose([
     transforms.CenterCrop(128),
     transforms.ToTensor(),])

transform6 = transforms.Compose([
    transforms.ToTensor(),])  

unloader = transforms.ToPILImage()

transform2 = transforms.Compose([
     transforms.RandomCrop(128),
     transforms.ToTensor(),])

transform3 = transforms.Compose([
     transforms.ToPILImage(),
     #transforms.RandomHorizontalFlip(),
     transforms.Resize(128),
     transforms.ToTensor(),])

transform4 = transforms.Compose([
     transforms.ToPILImage(),
     transforms.Resize((64, 64)),
     transforms.ToTensor(),])

transform5 = transforms.Compose([
     transforms.FiveCrop(128),
     transforms.ToTensor(),])

def image_loader(image_name, trans=None):
    image = Image.open(image_name).convert('RGB')
    if trans == transform1:
        image = transform1(image).unsqueeze(0)
    elif trans == transform2:
        image = transform2(image).unsqueeze(0)
    elif trans == transform3:
        image = transform2(image).unsqueeze(0)
    elif trans == transform4:
        image = transform4(image).unsqueeze(0)
    elif trans == transform5:
        image = transform5(image).unsqueeze(0)
    elif trans == transform6:
        image = transform6(image).unsqueeze(0)
    else:
        None
    return image

def image_loader2(image_name, trans=None):
    if trans == transform1:
        image = transform1(image_name).unsqueeze(0)
    elif trans == transform2:
        image = transform2(image_name).unsqueeze(0)
    elif trans == transform3:
        image = transform2(image_name).unsqueeze(0)
    elif trans == transform4:
        image = transform4(image_name).unsqueeze(0)
    elif trans == transform5:
        image = transform5(image_name).unsqueeze(0)
    elif trans == transform6:
        image = transform6(image_name).unsqueeze(0)
    else:
        None
    return image

x_train = torch.zeros(x_train_crop.shape[0],3,64,64)
for i in range(x_train_crop.shape[0]):
    #print(x_train_crop[i].shape)
    x_train[i,:,:,:] = transform4(x_train_crop[i])

x_test = torch.zeros(x_test_crop.shape[0],3,64,64)
for i in range(x_test_crop.shape[0]):
    #print(x_train_crop[i].shape)
    x_test[i,:,:,:] = transform4(x_test_crop[i])

y_train = torch.tensor(trainset["encoded_labels"])
y_test = torch.tensor(testset["encoded_labels"])

print(np.sum(trainset["encoded_labels"] == 0))  # bad
print(np.sum(trainset["encoded_labels"] == 1))  # good
print(np.sum(trainset["encoded_labels"] == 2))  # none

train_dataset = torch.utils.data.TensorDataset(x_train, y_train)
test_dataset = torch.utils.data.TensorDataset(x_test, y_test)
trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)
testloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)
trainloader

x_train2 = torch.empty(500, 3, 64, 64)
y_train2 = torch.empty(500, dtype=torch.long)
trainloader_temp = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)
u = np.random.random(x_train.shape[0])
i = 0

for j in range(x_train.shape[0]):
    #while i < 2358:
    if (int(y_train[j]) == 2):
        #print(y_train[j])
        y_train2[i] = y_train[j]
        x_train2[i,:,:,:] = x_train[j,:,:,:]
        i += 1
    elif (int(y_train[j]) == 0) and (u[j] >= 0.62):
        #print(y_train[j])
        y_train2[i] = y_train[j]
        x_train2[i,:,:,:] = x_train[j,:,:,:]
        i += 1 
    elif (int(y_train[j]) == 1) and (u[j] >= 0.9):
        #print(u[j])
        #print(y_train[j])
        y_train2[i] = y_train[j]
        x_train2[i,:,:,:] = x_train[j,:,:,:]
        i += 1
    if i == 500:
        break
#x_train2[2357,:,:,:]

train_dataset2 = torch.utils.data.TensorDataset(x_train2, y_train2)
trainloader2 = torch.utils.data.DataLoader(train_dataset2, batch_size=128, shuffle=True)
trainloader2

trainset_batchsize = trainloader.batch_size
testset_batchsize = testloader.batch_size
print(trainset_batchsize, testset_batchsize)

#optimizer = torch.optim.Adam(model.parameters(), lr=0.008, weight_decay=0.00)

class Classifier(torch.nn.Module):
    def __init__(self):
        super(Classifier, self).__init__()
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),  # [batch, 16, 128, 128]
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [batch, 16, 64, 64]

            torch.nn.Conv2d(64, 128, 3, 1, 1), # [batch, 32, 64, 64]
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [batch, 32, 32, 32]


        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(128*32*32, 512),
            torch.nn.LeakyReLU(),
            #torch.nn.Linear(1024, 512),
            #torch.nn.ReLU(),
            torch.nn.Linear(512, 3)
        )
    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)

class Classifier2(torch.nn.Module):
    def __init__(self):
        super(Classifier2, self).__init__()
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(3, 64, 1, 1, 0),  # [batch, 16, 128, 128]
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [batch, 16, 64, 64]

            #torch.nn.Conv2d(64, 128, 1, 1, 1), # [batch, 32, 64, 64]
            #torch.nn.BatchNorm2d(128),
            #torch.nn.ReLU(),
            #torch.nn.MaxPool2d(2, 2, 0),      # [batch, 32, 32, 32]


        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(64*32*32, 512),
            torch.nn.LeakyReLU(),
            #torch.nn.Linear(1024, 512),
            #torch.nn.ReLU(),
            torch.nn.Linear(512, 3)
        )
    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)

class Classifier3(torch.nn.Module):
    def __init__(self):
        super(Classifier3, self).__init__()
        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1)
        self.conv2 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)
        self.conv3 = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)
        self.pool = torch.nn.MaxPool2d(2, 2)
        self.fc1 = torch.nn.Linear(256 * 8 * 8, 1024)
        self.fc2 = torch.nn.Linear(1024, 512)
        self.fc3 = torch.nn.Linear(512, 3)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  #([100, 128, 64, 64])
        #print(x.shape)
        x = self.pool(F.relu(self.conv2(x)))  #([100, 256, 32, 32])
        x = self.pool(F.relu(self.conv3(x)))  #([100, 512, 16, 16])
        #print(x.shape)
        x = x.view(-1, 256 * 8 * 8)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        return self.fc3(x)

class Classifier4(torch.nn.Module):
    def __init__(self):
        super(Classifier4, self).__init__()
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        # torch.nn.MaxPool2d(kernel_size, stride, padding)
        # input 維度 [3, 128, 128]
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]

            torch.nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]

            torch.nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]
            torch.nn.BatchNorm2d(256),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]

            #nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]
            #nn.BatchNorm2d(512),
            #nn.ReLU(),
            #nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]
            
            #nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]
            #nn.BatchNorm2d(512),
            #nn.ReLU(),
            #nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]
        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(256 * 8 *8, 1024),
            torch.nn.ReLU(),
            torch.nn.Linear(1024, 512),
            torch.nn.ReLU(),
            torch.nn.Linear(512, 3)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)

class Classifier5(torch.nn.Module):
    def __init__(self):
        super(Classifier5, self).__init__()
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        # torch.nn.MaxPool2d(kernel_size, stride, padding)
        # input 維度 [3, 128, 128]
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(3, 32, 3, 1, 1),  # [32, 64, 64]
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [32, 32, 32]

            torch.nn.Conv2d(32, 64, 3, 1, 1), # [64, 32, 32]
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [64, 16, 16]

            torch.nn.Conv2d(64, 128, 3, 1, 1), # [128, 16, 16]
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [128, 8, 8]

            #nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]
            #nn.BatchNorm2d(512),
            #nn.ReLU(),
            #nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]
            
            #nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]
            #nn.BatchNorm2d(512),
            #nn.ReLU(),
            #nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]
        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(128 * 8 * 8, 512),
            torch.nn.ReLU(),
            torch.nn.Linear(512, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 3)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)

class Classifier6(torch.nn.Module):
    def __init__(self):
        super(Classifier6, self).__init__()
        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        # torch.nn.MaxPool2d(kernel_size, stride, padding)
        # input 維度 [3, 128, 128]
        self.cnn = torch.nn.Sequential(
            torch.nn.Conv2d(3, 64, 3, 1, 1),  # [64, 10, 10]
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2, 2, 0),      # [64, 32, 32]

            #torch.nn.Conv2d(32, 64, 3, 1, 1), # [64, 34, 34]
            #torch.nn.BatchNorm2d(64),
            #torch.nn.ReLU(),
            #torch.nn.MaxPool2d(2, 2, 0),      # [64, 17, 17]

            #torch.nn.Conv2d(64, 128, 3, 1, 1), # [128, 16, 16]
            #torch.nn.BatchNorm2d(128),
            #torch.nn.ReLU(),
            #torch.nn.MaxPool2d(2, 2, 0),      # [128, 8, 8]
        )
        self.fc = torch.nn.Sequential(
            torch.nn.Linear(64*32*32, 512),
            torch.nn.ReLU(),
            torch.nn.Linear(512, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 3)
        )

    def forward(self, x):
        out = self.cnn(x)
        out = out.view(out.size()[0], -1)
        return self.fc(out)

model = Classifier6().cuda()

loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
epochs = 50
t_train_loss = []
t_train_acc = []
t_test_loss = []
t_test_acc = []
train_pre = []
train_lab = []
test_pre = []
test_lab = []

for epoch in range(epochs):
    epoch_time_s = time.time()
    total = 0.0
    total_test = 0.0
    train_acc = 0.0
    train_loss = 0.0
    test_acc = 0.0
    test_loss = 0.0
    batch_loss = 0.0
    batch_loss1 = 0.0

    model.train()
    for i , data in enumerate(trainloader):
        inputs, labels = data
        #print(inputs)
        labels = labels.cuda()
        optimizer.zero_grad()
        #print(inputs[100])
        train_outputs = model(inputs.cuda())
        #print(train_outputs.shape)
        #print(labels.shape)
        batch_loss = loss(train_outputs, labels.cuda())
        batch_loss.backward()
        optimizer.step()
        #print(i)
        #prediction = np.argmax(train_outputs.data.cpu(), axis=1)
        _, prediction = torch.max(train_outputs.data, 1)
        #print(prediction)
        
        total += labels.size(0)
        train_acc += (prediction == labels).sum().item()
        #print(type(train_acc))
        train_loss += batch_loss.item()
        
        train_pre.append(prediction)
        train_lab.append(labels)
    
    total_train_acc = train_acc / total
    total_train_loss = train_loss / total
    t_train_acc.append(total_train_acc)
    t_train_loss.append(total_train_loss)
    
    model.eval()
    with torch.no_grad():
        for j, data in enumerate(testloader):
            inputs1, labels1 = data
            #print(inputs)
            
            labels1 = labels1.cuda()
            test_outputs = model(inputs1.cuda())
            
            batch_loss1 = loss(test_outputs, labels1.cuda())
            
            _, prediction1 = torch.max(test_outputs.data, 1)
            #print(j)
            #print(inputs1)
            #print(torch.max(test_outputs.data, 1))
            #print(test_outputs.data)
            total_test += labels1.size(0)
            test_acc += (prediction1 == labels1).sum().item()
            test_loss += batch_loss1.item()
            
            test_pre.append(prediction1)
            test_lab.append(labels1)
        
        total_test_acc = test_acc / total_test
        total_test_loss = test_loss / total_test
        t_test_acc.append(total_test_acc)
        t_test_loss.append(total_test_loss)
        
        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Test Acc: %3.6f loss: %3.6f' % \
            (epoch + 1, epochs, time.time()-epoch_time_s, \
             total_train_acc, total_train_loss, total_test_acc, total_test_loss))

#torch.save(model.state_dict(), 'model.ckpt')
#torch.save(model.state_dict(), 'model.pkl')

train_lab1 = torch.cat(train_lab).cpu().numpy()
train_pre1 = torch.cat(train_pre).cpu().numpy()
table = sklearn.metrics.confusion_matrix(train_lab1, train_pre1)
acc_bad = table[0,0] / np.sum(table[0,:])
acc_good = table[1,1] / np.sum(table[1,:])
acc_none = table[2,2] / np.sum(table[2,:])
Train_acc = {"good": acc_good, "none": acc_none, "bad": acc_bad}
test_lab1 = torch.cat(test_lab).cpu().numpy()
test_pre1 = torch.cat(test_pre).cpu().numpy()
table = sklearn.metrics.confusion_matrix(test_lab1, test_pre1)
acc_bad1 = table[0,0] / np.sum(table[0,:])
acc_good1 = table[1,1] / np.sum(table[1,:])
acc_none1 = table[2,2] / np.sum(table[2,:])
Test_acc = {"good": acc_good, "none": acc_none, "bad": acc_bad}
Accuracy = pd.DataFrame({'Train_acc': [acc_good, acc_none, acc_bad],
                         'Test_acc': [acc_good1, acc_none1, acc_bad1]},
                         index=["good", "none", "bad"])
#Accuracy = pd.DataFrame.from_dict(Accuracy)
#rownames(Accuracy) = ["good", "none", "bad"]

Accuracy

results6 = {"train accuracy":t_train_acc, "train loss": t_train_loss, "test accuracy": t_test_acc, "test loss": t_test_loss}

def loss_acc(results):
    xlim = range(epochs)
    plt.figure(figsize=(14, 6))
    plt.subplot(1,2,1)
    plt.plot(xlim, results["train loss"], color="blue", label='train')
    plt.plot(xlim, results["test loss"], color="orange", label='testn')
    plt.legend()
    plt.title("Learning Curve")
    plt.xlabel("Number of epochs")
    plt.ylabel("Cross Entropy")
    plt.subplot(1,2,2)
    plt.plot(xlim, results["train accuracy"], color="blue", label='train')
    plt.plot(xlim, results["test accuracy"], color="orange", label='test')
    plt.legend(loc='upper right')
    plt.title("Training Accuracy")
    plt.xlabel("Number of epochs")
    plt.ylabel("Accuracy Rate")
    plt.show()

loss_acc(results6)

model = Classifier6().cuda()
#model.cuda()
#model = Classifier().cuda()
loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)
epochs = 50
t_train_loss = []
t_train_acc = []
t_test_loss = []
t_test_acc = []
train_pre = []
train_lab = []
test_pre = []
test_lab = []

for epoch in range(epochs):
    epoch_time_s = time.time()
    total = 0.0
    total_test = 0.0
    train_acc = 0.0
    train_loss = 0.0
    test_acc = 0.0
    test_loss = 0.0
    batch_loss = 0.0
    batch_loss1 = 0.0

    model.train()
    for i , data in enumerate(trainloader):
        inputs, labels = data
        
        labels = labels.cuda()
        
        optimizer.zero_grad()
        #print(inputs[100])
        train_outputs = model(inputs.cuda())
        #print(labels.type)
        batch_loss = loss(train_outputs, labels.cuda())
        
        batch_loss.backward()
        optimizer.step()
        #print(i)
        #prediction = np.argmax(train_outputs.data.cpu(), axis=1)
        _, prediction = torch.max(train_outputs.data, 1)
        #print(prediction)
        
        total += labels.size(0)
        train_acc += (prediction == labels).sum().item()
        #print(type(train_acc))
        train_loss += batch_loss.item()
        
        train_pre.append(prediction)
        train_lab.append(labels)
    
    total_train_acc = train_acc / total
    total_train_loss = train_loss / total
    t_train_acc.append(total_train_acc)
    t_train_loss.append(total_train_loss)
    
    model.eval()
    with torch.no_grad():
        for j, data in enumerate(testloader):
            inputs1, labels1 = data
            #print(inputs)
            labels1 = labels1
            labels1 = labels1.cuda()
            #print(tensor.type(input1))
            test_outputs = model(inputs1.cuda())
            
            batch_loss1 = loss(test_outputs, labels1.cuda())
            
            _, prediction1 = torch.max(test_outputs.data, 1)
            #print(j)
            #print(inputs1)
            #print(torch.max(test_outputs.data, 1))
            #print(test_outputs.data)
            total_test += labels1.size(0)
            test_acc += (prediction1 == labels1).sum().item()
            test_loss += batch_loss1.item()
            
            test_pre.append(prediction1)
            test_lab.append(labels1)
        
        total_test_acc = test_acc / total_test
        total_test_loss = test_loss / total_test
        t_test_acc.append(total_test_acc)
        t_test_loss.append(total_test_loss)
        
        print('[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Test Acc: %3.6f loss: %3.6f' % \
            (epoch + 1, epochs, time.time()-epoch_time_s, \
             total_train_acc, total_train_loss, total_test_acc, total_test_loss))

train_lab1 = torch.cat(train_lab).cpu().numpy()
train_pre1 = torch.cat(train_pre).cpu().numpy()
table = sklearn.metrics.confusion_matrix(train_lab1, train_pre1)
acc_bad = table[0,0] / np.sum(table[0,:])
acc_good = table[1,1] / np.sum(table[1,:])
acc_none = table[2,2] / np.sum(table[2,:])
Train_acc = {"good": acc_good, "none": acc_none, "bad": acc_bad}
test_lab1 = torch.cat(test_lab).cpu().numpy()
test_pre1 = torch.cat(test_pre).cpu().numpy()
table = sklearn.metrics.confusion_matrix(test_lab1, test_pre1)
acc_bad1 = table[0,0] / np.sum(table[0,:])
acc_good1 = table[1,1] / np.sum(table[1,:])
acc_none1 = table[2,2] / np.sum(table[2,:])
Test_acc = {"good": acc_good, "none": acc_none, "bad": acc_bad}
Accuracy = pd.DataFrame({'Train_acc': [acc_good, acc_none, acc_bad],
                         'Test_acc': [acc_good1, acc_none1, acc_bad1]},
                         index=["good", "none", "bad"])
#Accuracy = pd.DataFrame.from_dict(Accuracy)
#rownames(Accuracy) = ["good", "none", "bad"]

Accuracy
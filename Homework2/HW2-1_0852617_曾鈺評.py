# -*- coding: utf-8 -*-
"""0852617_dl_hw2-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hi504aYipfPxeFwXqN8Aq2-zT6__04kG
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader, TensorDataset
from tqdm.notebook import tqdm

# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools
# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
# !apt-get update -qq 2>&1 > /dev/null
# !apt-get -y install -qq google-drive-ocamlfuse fuse
# from google.colab import auth
# auth.authenticate_user()
# from oauth2client.client import GoogleCredentials
# creds = GoogleCredentials.get_application_default()
# import getpass
# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
# vcode = getpass.getpass()
# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
#auth.authenticate_user()
#gauth = GoogleAuth()
#gauth.credentials = GoogleCredentials.get_application_default()

gauth = GoogleAuth()
gauth.LoadCredentialsFile("mycreds.txt")
if gauth.credentials is None:
  auth.authenticate_user()   
  gauth.credentials = GoogleCredentials.get_application_default()
    
elif gauth.access_token_expired:
  gauth.Refresh()
    
else:
  gauth.Authorize()
gauth.SaveCredentialsFile("mycreds.txt")
drive = GoogleDrive(gauth)



#gauth.SaveCredentialsFile("mycreds.txt")
#gauth.LoadCredentialsFile("mycreds.txt")
#drive = GoogleDrive(gauth)

link = 'https://drive.google.com/open?id=1FnS_Kd_QLaQKWbYNf0z3-pdTkFZqG4Vz'
fluff, id = link.split('=')
print (id)
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('covid_19.csv')

data_covid = pd.read_csv('covid_19.csv', index_col=0)

data_covid

"""i Please compute the correlation coecient between two countries. The correlation coeffcient function is expressed by"""

df_covid = data_covid.drop(['Lat', 'Long'],axis=1)
df_covid = df_covid.iloc[2:]
df_covid.iloc[:, :] = df_covid.iloc[:, :].astype(int)
df_covid = df_covid
df_covid

df_covid_new = np.zeros_like(df_covid)
for i in range(df_covid.shape[1]-1):
  #print(i)
  df_covid_new[:,i+1] = df_covid.iloc[:,i+1] - df_covid.iloc[:,i]
  #print(len(df_covid_new[:,i]))
df_covid_x = pd.DataFrame(df_covid_new[:,1:df_covid.shape[1]], index=df_covid.index, columns=df_covid.columns[1:])
df_covid_x.iloc[:,-12:]

corr_matrix = df_covid_x.transpose().corr()
corr_matrix

threshold_matrix = abs(corr_matrix) > 0.7
selected_country = []
unselected_country = []
#print(test)
for i in range(len(threshold_matrix)):
  if np.sum(threshold_matrix.iloc[i]) > 1:
    selected_country.append(threshold_matrix.columns[i])
  else:
    unselected_country.append(threshold_matrix.columns[i])
print(selected_country)
print("total selected country: %i" % len(selected_country))
df_covid_train = df_covid_x.loc[selected_country]
df_covid_train

df_covid_y1 = np.matrix(df_covid_x.iloc[:,:(df_covid_x.shape[1]-1)])
df_covid_y2 = np.matrix(df_covid_x.iloc[:,1:])

df_covid_y = pd.DataFrame(df_covid_y2 > df_covid_y1, columns=df_covid_x.iloc[:,1:].columns, index=df_covid_x.index)*1
df_covid_y

sns.set(style='white')
corr = corr_matrix.iloc[:10,:10]
print(corr)
mask = np.triu(np.ones_like(corr, dtype=np.bool)) # Generate a mask for the upper triangle
fig, ax = plt.subplots(figsize=(10,10))
cmap =  sns.color_palette("Reds", 1000)
sns.heatmap(corr, mask=mask,  cmap=cmap, vmax=1, vmin=-1)



L = 5

def sequence_data(L, country, df_covid_x=df_covid_x, df_covid_y = df_covid_y):
  x = []
  y = []
  for i in range(len(country)): 
    for j in range(df_covid_x.shape[1] - L): 
      x_sub = np.array(df_covid_x.loc[country[i]][j:j+L])
      y_sub = df_covid_y.loc[country[i]][j+L-1]
      x.append(x_sub)
      y.append(y_sub)
  return np.array(x), np.array(y)

x_train, y_train = sequence_data(L=L, country=selected_country)
x_test, y_test = sequence_data(L=L, country=unselected_country)

x_train_torch = torch.from_numpy(x_train).unsqueeze(2).permute(1,0,2).to(torch.float32)
x_test_torch = torch.from_numpy(x_test).unsqueeze(2).permute(1,0,2).to(torch.float32)
y_train_torch = torch.from_numpy(y_train).unsqueeze(1).long()
y_test_torch = torch.from_numpy(y_test).unsqueeze(1).long()
y_train_torch_1d = torch.from_numpy(y_train).long()
y_test_torch_1d = torch.from_numpy(y_test).long()

print(x_train_torch.shape)
print(x_test_torch.shape)
print(y_train_torch.shape)
print(y_test_torch.shape)
print(y_train_torch_1d.shape)

# check GPU is available
is_cuda = torch.cuda.is_available()
if is_cuda:
  device = torch.device("cuda")
  print("GPU is available")
else:
  device = torch.device("cpu")
  print("GPU is not available")

#A.cuda() ; A.to(device)

# Create RNN
input_dim = 1    # input dimension
hidden_len = 2  # hidden layer dimension
layer_dim = 10    # number of hidden layers
output_dim = 1   # output dimension


class SimpleRNN(nn.Module):
  def __init__(self, input_dim, hidden_len, layer_dim, output_dim):  #, batch_size
    super(SimpleRNN, self).__init__()

    self.hidden_len = hidden_len
    self.layer_dim = layer_dim
    self.rnn = nn.RNN(input_dim, hidden_len, layer_dim)  #, batch_first=True

  def forward(self, x):
    output, hn = self.rnn(x) #
    #output1 = nn.Softmax(output[-1])
    output = F.softmax(output[-1], dim=1)
    return output

model_RNN = SimpleRNN(input_dim=input_dim, hidden_len=hidden_len, layer_dim=layer_dim, output_dim=output_dim).to(torch.float32)  
criterion = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() 
optimizer = torch.optim.Adam(model_RNN.parameters(), lr=0.001)


loss_list1 = []
loss_test_list1 = []
accuracy_list1 = []
accuracy_test_list1 = []
model_RNN.to(device)
for epoch in tqdm(range(2000)):  #num_epochs

    model_RNN.train()
    x_train = x_train_torch.to(device)
    y_train = y_train_torch_1d.to(device)

       
    # Clear gradients
    optimizer.zero_grad()
        
    # Forward propagation
    output = model_RNN(x_train)
    #print(output)

    #print(output)
    # Calculate softmax and ross entropy loss
    loss = criterion(output.float(), y_train)
    loss_list1.append(loss)
        
    # Calculating gradients
    loss.backward()
        
    # Update parameters
    optimizer.step()
        


    #acc = (output.round() == y_train).float().mean()  #for 1D
    acc = (output.argmax(dim=1) == y_train).float().mean()
    accuracy_list1.append(acc)

    model_RNN.eval()
    with torch.no_grad():
      x_test = x_test_torch.to(device)
      y_test = y_test_torch_1d.to(device)
      output_test = model_RNN(x_test)
      loss_test = criterion(output_test.float(), y_test)
      loss_test_list1.append(loss_test)
      acc_test = (output_test.argmax(dim=1) == y_test).float().mean()
      accuracy_test_list1.append(acc_test)

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2, 1)
plt.plot(loss_list1)
plt.title('loss of training set by RNN')
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('RNN_loss_list_2')
plt.subplot(1,2,2)
plt.plot(loss_test_list1)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('RNN_loss_test_list_1')
plt.show()

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(accuracy_list1)
plt.title('accracy of training set by RNN')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('RNN_accuracy_list_2')
plt.subplot(1,2,2)
plt.plot(accuracy_test_list1)
plt.title('accuracy of testing set by RNN')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('RNN_accuracy_test_list_1')
plt.show()

print(min(accuracy_list1))
print(max(accuracy_list1))
print(min(accuracy_test_list1))
print(max(accuracy_test_list1))

# Create LSTM
input_dim = 1    # input dimension
hidden_len = 2  # hidden layer dimension
layer_dim = 3    # number of hidden layers
output_dim = 1   # output dimension


class LSTM(nn.Module):
  def __init__(self, input_dim, hidden_len, layer_dim, output_dim):  
    super(LSTM, self).__init__()

    self.hidden_len = hidden_len
    self.layer_dim = layer_dim
    self.lstm = nn.LSTM(input_dim, hidden_len, layer_dim)  

  def forward(self, x):
    output, hn = self.lstm(x) 
    output = F.softmax(output[-1], dim=1)
    return output

model_LSTM = LSTM(input_dim=input_dim, hidden_len=hidden_len, layer_dim=layer_dim, output_dim=output_dim).to(torch.float32) 
criterion = nn.CrossEntropyLoss()  #nn.CrossEntropyLoss() 
optimizer = torch.optim.Adam(model_LSTM.parameters(), lr=0.001) 


loss_list2 = []
loss_test_list2 = []
accuracy_list2 = []
accuracy_test_list2 = []
model_LSTM.to(device)
for epoch in tqdm(range(2000)):  #num_epochs

    model_LSTM.train()
    x_train = x_train_torch.to(device)
    y_train = y_train_torch_1d.to(device)
       
    # Clear gradients
    optimizer.zero_grad()
        
    # Forward propagation
    output = model_LSTM(x_train)

    #print(output)
    # Calculate softmax and ross entropy loss
    loss = criterion(output.float(), y_train)
    loss_list2.append(loss)
        
    # Calculating gradients
    loss.backward()
        
    # Update parameters
    optimizer.step()
        


    #acc = (output.round() == y_train).float().mean()  #for 1D
    acc = (output.argmax(dim=1) == y_train).float().mean()
    accuracy_list2.append(acc)

    model_LSTM.eval()
    with torch.no_grad():
      x_test = x_test_torch.to(device)
      y_test = y_test_torch_1d.to(device)
      output_test = model_LSTM(x_test)
      loss_test = criterion(output_test.float(), y_test)
      loss_test_list2.append(loss_test)
      acc_test = (output_test.argmax(dim=1) == y_test).float().mean()
      accuracy_test_list2.append(acc_test)

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(loss_list2)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('LSTM_loss_list_1')
plt.subplot(1,2,2)
plt.plot(loss_test_list2)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('LSTM_loss_testlist_1')
plt.show()

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(accuracy_list2)
plt.title('accuracy of training set by LSTM')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('LSTM_accuracy_list_1')
plt.subplot(1,2,2)
plt.plot(accuracy_test_list2)
plt.title('accuracy of testing set by LSTM')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('LSTM_accuracy_test_list_1')
plt.show()

print(min(accuracy_list2))
print(max(accuracy_list2))
print(min(accuracy_test_list2))
print(max(accuracy_test_list2))


# Create GRU
input_dim = 1    # input dimension
hidden_len = 2  # hidden layer dimension
layer_dim = 3    # number of hidden layers
output_dim = 1   # output dimension


class GRU(nn.Module):
  def __init__(self, input_dim, hidden_len, layer_dim, output_dim):  
    super(GRU, self).__init__()
    self.hidden_len = hidden_len
    self.layer_dim = layer_dim
    self.gru = nn.GRU(input_dim, hidden_len, layer_dim)  

  def forward(self, x):
    output, hn = self.gru(x) 
    output = F.softmax(output[-1], dim=1)
    return output

model_GRU = GRU(input_dim=input_dim, hidden_len=hidden_len, layer_dim=layer_dim, output_dim=output_dim).to(torch.float32) 
criterion = nn.CrossEntropyLoss() 
optimizer = torch.optim.Adam(model_GRU.parameters(), lr=0.001)


loss_list3 = []
loss_test_list3 = []
accuracy_list3 = []
accuracy_test_list3 = []
model_GRU.to(device)
for epoch in tqdm(range(1000)):  #num_epochs

    model_GRU.train()
    x_train = x_train_torch.to(device)
    y_train = y_train_torch_1d.to(device)

    # Clear gradients
    optimizer.zero_grad()
        
    # Forward propagation
    output = model_GRU(x_train)

    #print(output)
    # Calculate softmax and ross entropy loss
    loss = criterion(output.float(), y_train)
    loss_list3.append(loss)
        
    # Calculating gradients
    loss.backward()
        
    # Update parameters
    optimizer.step()
        


    #acc = (output.round() == y_train).float().mean()  #for 1D
    acc = (output.argmax(dim=1) == y_train).float().mean()
    accuracy_list3.append(acc)

    model_GRU.eval()
    with torch.no_grad():
      x_test = x_test_torch.to(device)
      y_test = y_test_torch_1d.to(device)
      output_test = model_GRU(x_test)
      loss_test = criterion(output_test.float(), y_test)
      loss_test_list3.append(loss_test)
      acc_test = (output_test.argmax(dim=1) == y_test).float().mean()
      accuracy_test_list3.append(acc_test)

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(loss_list3)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('GRU_loss_list_1')
plt.subplot(1,2,2)
plt.plot(loss_test_list3)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('GRU_loss_testlist_1')
plt.show()

fig = plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(accuracy_list3)
plt.title('accuracy of training set by GRU')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('GRU_accuracy_list_1')
plt.subplot(1,2,2)
plt.plot(accuracy_test_list3)
plt.title('accuracy of testing set by GRU')
plt.xlabel('iteration')
plt.ylabel('accuracy')
plt.savefig('GRU_accuracy_test_list_1')
plt.show()

print(min(accuracy_list3))
print(max(accuracy_list3))
print(min(accuracy_test_list3))
print(max(accuracy_test_list3))



!pip install pygal
!pip install pygal_maps_world
!pip install cairosvg

import pygal
import pygal_maps_world
from pygal_maps_world.maps import World
from pygal_maps_world.maps import SupranationalWorld
from pygal_maps_world.maps import COUNTRIES

#from pygal import World

#!pip install countrycode

x_pred = torch.from_numpy(np.array(df_covid_x.iloc[:,(-1*L):])).unsqueeze(2).permute(1,0,2).to(torch.float32)
pred_prob, pred_output = torch.max(model_LSTM(x_pred), dim=1)
pred_prob_np = pred_prob.detach().numpy()
pred_output_np = pred_output.numpy()

rename = {
    'Bolivia': 'Bolivia, Plurinational State of',
    'Brunei': 'Brunei Darussalam',
    'Congo (Brazzaville)': 'Congo, the Democratic Republic of the',
    'Congo (Kinshasa)': 'Congo',
    'Dominica': 'Dominican Republic',
    'Holy See': 'Holy See (Vatican City State)',
    'Iran': 'Iran, Islamic Republic of',
    'Korea, South': 'Korea, Republic of',
    'Laos': "Lao People's Democratic Republic",
    'Libya': 'Libyan Arab Jamahiriya',
    'Moldova': 'Moldova, Republic of',
    'North Macedonia': 'Macedonia, the former Yugoslav Republic of',
    'Russia': 'Russian Federation',
    'South Sudan': 'Sudan',
    'Syria': 'Syrian Arab Republic',
    'Taiwan*': 'Taiwan, Province of China',
    'Tanzania': 'Tanzania, United Republic of',
    'Venezuela': 'Venezuela, Bolivarian Republic of',
    'Vietnam': 'Viet Nam',
    'Burma': 'Myanmar',
    'Cabo Verde': 'Cape Verde',
    'Eswatini': 'Swaziland',
    'Czechia': 'Czech Republic',
    'US': 'United States',
}

def get_country_code(country_name):
    for code,name in COUNTRIES.items():
        if name==country_name:
            return code
    return None

df_covid_x_rename = df_covid_x.rename(index=rename)

ascending = df_covid_x_rename.iloc[np.where(pred_output_np==1)].index
descending = df_covid_x_rename.iloc[np.where(pred_output_np==0)].index
ascending_prob = list(pred_prob_np[i] for i in np.where(pred_output_np==1)[0].tolist())
descending_prob = list(pred_prob_np[i] for i in np.where(pred_output==0)[0].tolist())

ascending_country_code = [get_country_code(i) for i in ascending]
descending_country_code = [get_country_code(i) for i in descending]

ascending_dict = dict(zip(ascending_country_code, ascending_prob))
descending_dict = dict(zip(descending_country_code, descending_prob))

worldmap_chart = World()
worldmap_chart.title = 'Prediction of Covid-19'
worldmap_chart.add('Ascending', ascending_dict)
worldmap_chart.add('Descending', descending_dict)

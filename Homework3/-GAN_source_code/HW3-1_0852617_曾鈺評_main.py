# -*- coding: utf-8 -*-
"""HW3_1_0852617_曾鈺評.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18_twaI6bPoZd_4dA283I9CY4wbgDgdNv
"""

import os
from google.colab import drive
#os.getcwd()
drive.mount('/content/drive', force_remount=True)
os.chdir('/content/drive/My Drive/Colab Notebooks/GAN_source_code')
workspace_dir = os.getcwd()

from __future__ import print_function
#%matplotlib inline
import argparse
import os
import cv2
import random
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.backends.cudnn as cudnn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import argparse
from IPython.display import HTML
from Model import *
from tqdm import tqdm
from torch.autograd import Variable

# Set random seed for reproducibility
manualSeed = 999
#manualSeed = random.randint(1, 10000) # use if you want new results
print("Random Seed: ", manualSeed)
random.seed(manualSeed)
torch.manual_seed(manualSeed)

ngpu = 1
device = torch.device("cuda:0" if (torch.cuda.is_available() and ngpu > 0) else "cpu")

def common_arg_parser():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--dataroot', default='data/celeba', type=str)
    parser.add_argument('--batch_size', default=128, type=int)
    parser.add_argument('--image_size', default=64, type=int)
    parser.add_argument('--num_epochs', default=5, type=int)
    parser.add_argument('--lr', default=0.0002, type=float)
    

    return parser

# Create the dataset by using ImageFolder(get extra point by using customized dataset)
# remember to preprocess the image by using functions in pytorch
dataset = np.load('hw3_1_size64_new1.npy')
#dataset_1 = torch.from_numpy(dataset[0:202599,:,:,:])
# Create the dataloader 
#dataloader = torch.utils.data.DataLoader(dataset_1, batch_size = batch_size, shuffle=True)

dataset = dataset.transpose(0, 2, 3, 1)

class FaceDataset(Dataset):
    def __init__(self, fnames, transform):
        self.transform = transform
        self.fnames = fnames
        self.num_samples = len(self.fnames)
    def __getitem__(self,idx):
        fname = self.fnames[idx]
        img = self.transform(fname)
        return img

    def __len__(self):
        return self.num_samples

    def BGR2RGB(self,img):
        return cv2.cvtColor(img,cv2.COLOR_BGR2RGB)

def get_dataset(fnames):
    transform = transforms.Compose(
        [transforms.ToPILImage(),
         transforms.RandomHorizontalFlip(p=0.5),
         #transforms.Resize((64, 64)),
         transforms.ToTensor(),
         transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3) ] )
    dataset = FaceDataset(fnames, transform)
    return dataset

def get_sample(fnames):
    transform = transforms.Compose(
        [#transforms.ToPILImage(),
         #transforms.Resize((64, 64)),
         transforms.ToTensor(),
         transforms.Normalize(mean=[0.5] * 3, std=[0.5] * 3) ] )
    dataset = FaceDataset(fnames, transform)
    return dataset

train_image = get_dataset(dataset)
# Another way to get train_image
#train_image = torch.from_numpy(dataset).to(device, dtype=float)

#plt.imshow(dataset[10])

batch_size=64
lr=0.0002
num_epochs=5
dataloader = torch.utils.data.DataLoader(train_image, batch_size = batch_size, shuffle=True)

for j in range(1):
    
    # Create the generator and the discriminator()
    # Initialize them 
    # Send them to your device
    generator = Generator(ngpu).to(device)
    discriminator = Discriminator(ngpu).to(device)
    generator.train()
    discriminator.train()

    z_0  =  torch.randn(batch_size, 100, 1, 1).to(device, dtype=torch.float)
    

    # Setup optimizers for both G and D and setup criterion at the same time
    optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
    #optimizer_g = torch.optim.RMSprop(generator.parameters(), lr=lr)
    optimizer_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))
    #optimizer_d = torch.optim.RMSprop(discriminator.parameters(), lr=lr/2)
    criterion = nn.BCELoss()
    
    # Start training~~
    loss_G_total = []
    loss_D_total = []
    # Each epoch, we have to go through every data in dataset
    for epoch in tqdm(range(num_epochs)):
        # Each iteration, we will get a batch data for training
        for i, data in enumerate(dataloader, 0):

            # initialize gradient for network
            # send the data into device for computation
            real_imgs = data.to(device, dtype=torch.float)
            batch_size1  = real_imgs.size(0)
  
            # Send data to discriminator and calculate the loss and gradient
            # For calculate loss, you need to create label for your data
            real_logit = discriminator(real_imgs)  #.detach()
            real_label = torch.ones((batch_size1)).to(device)
            real_loss = criterion(real_logit, real_label)
            
            ## Using Fake data, other steps are the same.
            # Generate a batch fake data by using generator
            z = torch.randn(batch_size1, 100 , 1, 1).to(device, dtype=torch.float)  #z_dim=100
            fake_imgs = generator(z)            

            # Send data to discriminator and calculate the loss and gradient
            # For calculate loss, you need to create label for your data
            
            fake_logit = discriminator(fake_imgs)
            fake_label = torch.zeros((batch_size1)).to(device)      
            fake_loss = criterion(fake_logit, fake_label)
            loss_D = (real_loss + fake_loss) / 2

            # Update your network
            discriminator.zero_grad()
            loss_D.backward()
            optimizer_d.step()

            # train G
            # leaf
            z = torch.randn(batch_size1, 100 , 1, 1).to(device, dtype=torch.float)  #z_dim=100
            fake_imgs = generator(z)

            # dis
            fake_logit = discriminator(fake_imgs)
        
            # compute loss
            loss_G = criterion(fake_logit, real_label)

            # update model
            generator.zero_grad()
            loss_G.backward()
            optimizer_g.step()
            
            # Record your loss every iteration for visualization
            loss_D_total.append(loss_D)
            loss_G_total.append(loss_G)
            
            # Use this function to output training procedure while training
            # You can also use this function to save models and samples after fixed number of iteration
            if i % 50 == 0:  #50
                #print('success')
                print('epoch [{}/{}]  {}/{}, loss_D:{:.3f}, loss_G:{:.3f}'.format(epoch+1, num_epochs, i+1, len(dataloader), loss_D, loss_G))
        sample_image = generator(z_0)
        with torch.no_grad():
            fig = plt.figure(figsize = (12,12))
            a=0
            for k in range(64):
                fig.add_subplot(8,8,k+1)
                plt.xticks([])
                plt.yticks([])
                plt.imshow(sample_image[k].data.permute(1,2,0).add_(1).div_(2).cpu())
            plt.savefig('./image/samples3_epoch{}'.format(epoch+1))
            plt.show();

        # Remember to save all things you need after all batches finished!!!
        torch.save(generator.state_dict(), './checkpoint/checkpoint3_G_{}.pth'.format(epoch+1))
        torch.save(discriminator.state_dict(), './checkpoint/checkpoint3_D_{}.pth'.format(epoch+1))

loss_D_total = [i.data.cpu() for i in loss_D_total]  #[0:7500]
loss_G_total = [i.data.cpu() for i in loss_G_total]  #[0:7500]
fig = plt.figure(figsize=(20,10)) 
ax = plt.axes()
x = np.linspace(0, len(loss_D_total), len(loss_D_total))
ax.plot(x, loss_D_total)
ax.plot(x, loss_G_total)
plt.xlabel('iteration')
plt.ylabel('loss')
plt.savefig('{}/loss_image4'.format(workspace_dir))
plt.show()

